<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Emily Schultz" />

<meta name="date" content="2023-02-15" />

<title>ESS 3500 R Handbook, Lesson 6</title>

<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ESS 3500 R Handbook</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Lessons
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="RHandbook_1.html">Lesson 1: Software installation</a>
    </li>
    <li>
      <a href="RHandbook_2.html">Lesson 2: R Basics</a>
    </li>
    <li>
      <a href="RHandbook_3.html">Lesson 3: Data frames</a>
    </li>
    <li>
      <a href="RHandbook_4.html">Lesson 4: Distributions and descriptive statistics</a>
    </li>
    <li>
      <a href="RHandbook_5.html">Lesson 5: Two-sample t-test</a>
    </li>
    <li>
      <a href="RHandbook_6.html">Lesson 6: Assumptions and transformations</a>
    </li>
    <li>
      <a href="RHandbook_7.html">Lesson 7: Variations on the t-test</a>
    </li>
    <li>
      <a href="RHandbook_8.html">Lesson 8: ANOVA</a>
    </li>
    <li>
      <a href="RHandbook_9.html">Lesson 9: Correlations</a>
    </li>
    <li>
      <a href="RHandbook_10.html">Lesson 10: Regressions</a>
    </li>
    <li>
      <a href="RHandbook_11.html">Lesson 11: Multiple predictors</a>
    </li>
    <li>
      <a href="RHandbook_12.html">Lesson 12: Categorical data</a>
    </li>
  </ul>
</li>
<li>
  <a href="RHandbook_templates.html">R Templates</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">ESS 3500 R Handbook, Lesson 6</h1>
<h4 class="author">Emily Schultz</h4>
<h4 class="date">2023-02-15</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#lesson-6-assumptions-and-transformations"
id="toc-lesson-6-assumptions-and-transformations">Lesson 6: Assumptions
and Transformations</a>
<ul>
<li><a href="#testing-for-normality" id="toc-testing-for-normality">6.1
Testing for normality</a></li>
<li><a href="#the-log-transform" id="toc-the-log-transform">6.2 The log
transform</a></li>
<li><a href="#testing-for-equal-variances"
id="toc-testing-for-equal-variances">6.3 Testing for equal
variances</a></li>
<li><a href="#the-square-root-transform"
id="toc-the-square-root-transform">6.4 The square root
transform</a></li>
<li><a href="#running-the-test" id="toc-running-the-test">6.5 Running
the test</a></li>
<li><a href="#welchs-tests" id="toc-welchs-tests">6.6 Welch’s
tests</a></li>
<li><a href="#practice-problems" id="toc-practice-problems">Practice
problems</a></li>
</ul></li>
</ul>
</div>

<div id="lesson-6-assumptions-and-transformations"
class="section level2">
<h2>Lesson 6: Assumptions and Transformations</h2>
<p>In this lesson, we will cover how to test two assumptions (normality
and equal variances) of t-tests and other similar models and what to do
when the assumptions are violated. Note that these assumptions apply
whether we are using a classical frequentist approach or a maximum
likelihood approach, and the methods we use for testing and addressing
violations of assumptions is the same for both.</p>
<p>For this lesson, we will work with a new data set that contains data
from an experiment that was done to test for the effect of invasive
grass removal on the plant community. As a first pass, the researchers
simply wanted to know if removing the grasses from the plot at the start
of the growing season was effective for reducing the invasive grass
cover in the plot at the end of the growing season. You will work with
two variables from this data set. Your independent variable is weed
removal (the name of this variable is “Weed” in the data set), and your
dependent variable is grass cover (the name of this variable is
“Grass_cover” in the data set). Because we have a categorical
independent variable with two values and a continuous dependent
variable, a t-test is an appropriate test for these data, if the
assumptions are met.</p>
<p>Download the InvasiveGrass.csv file from Canvas. Set your working
directory in R to the folder that contains the data file.</p>
<p>Then load your data file into R using the usual ‘read.csv’ function.
I am calling the data object “grass” for this example.</p>
<pre class="r"><code>grass &lt;- read.csv(&quot;InvasiveGrass.csv&quot;)</code></pre>
<p>We will also use the <strong>ggplot2</strong> package for this
lesson, so load that package now as well:</p>
<pre class="r"><code>library(ggplot2)</code></pre>
<div id="testing-for-normality" class="section level3">
<h3>6.1 Testing for normality</h3>
<p>The assumption normality for t-tests is that the residuals (the
leftover variation that is not explained by our model) are normally
distributed. Therefore, in order to test this assumption, we need to
first run our model and save the residuals to test.</p>
<p>We will run a t-test using the ‘lm’ function, just like we did in the
t-test lesson when we used the maximum likelihood approach, and we will
store the test output in an object called “grass_ttest”. We use the ‘lm’
function instead of the ‘t.test’ function because the ‘t.test’ function
doesn’t save the residuals from the test. However, the models built by
the two functions are exactly the same, so the residuals are the same
regardless of the approach we use to test the models. We can still
choose to use either approach after checking our assumptions.</p>
<pre class="r"><code>grass_ttest &lt;- lm(Grass_cover ~ Weed, data = grass)</code></pre>
<p>We will now save the residuals from the model using the
<code>resid</code> function. Then we will store the residuals in a data
frame, so we can graph them using <code>ggplot</code>. We will store the
residuals in a data frame called “resids” and the variable name within
the data frame will be “Residuals”.</p>
<pre class="r"><code># Save residuals
grass_resid &lt;- resid(grass_ttest)

# Store residuals in a data frame
resids &lt;- data.frame(Residuals = grass_resid)</code></pre>
<p>Now that we have saved our residuals, we can move on to testing
whether they are normally distributed.</p>
<div id="histogram-of-residuals" class="section level4">
<h4>Histogram of residuals</h4>
<p>The first way to check for normality of residuals is to make a
histogram to determine if the residuals look like they are normally
distributed, or at least symmetrical. We will makes this graph using the
residuals that we saved from our model in the previous section.</p>
<pre class="r"><code>ggplot(resids, aes(x=Residuals)) +
  geom_histogram() +
  labs(x=&quot;Grass cover&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="RHandbook_6_files/figure-html/residalt_hist-1.png" width="672" /></p>
<p>Do the residuals look normally distributed?</p>
</div>
<div id="qqplot" class="section level4">
<h4>qqplot</h4>
<p>There is another type of graph that is useful for visualizing the
normality of residuals, called a qqplot. This type of graph compares the
residuals from a model with residuals that would be predicted based on a
normal distribution. If we graph the residuals from our model against
the predicted residuals, we would expect them to form a straight line if
the residuals are normally distributed. If they do not form a straight
line, that suggests the residuals are not normally distributed.</p>
<p>To make a qqplot to test for a normal distribution, we can use the
<code>qqnorm</code> function. Then we can use the <code>qqline</code>
function to add a reference line to the plot, showing where the points
should fall if the data are normally distributed. The input (argument)
for both of these functions in the object with our saved residuals
(grass_resid).</p>
<pre class="r"><code>qqnorm(grass_resid)
qqline(grass_resid)</code></pre>
<p><img src="RHandbook_6_files/figure-html/qqplots-1.png" width="672" /></p>
<p>When the points fall close to the line like this, that means that the
distribution of our residuals is close to normal. Based on both types of
graphs, it looks like our data are normally distributed, but we’ll cover
a formal test for this as well.</p>
</div>
<div id="shapiro-wilks-test" class="section level4">
<h4>Shapiro-Wilks test</h4>
<p>The Shapiro-Wilks test is a formal test to determine if a
distribution is normal. Our null hypothesis for this test is that the
residuals are normally distributed.</p>
<p>Running the test is pretty straightforward. We will use the
<code>shapiro.test</code> function, and the only argument we need to
input is our residuals from the models we built.</p>
<pre class="r"><code>shapiro.test(grass_resid)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  grass_resid
## W = 0.95069, p-value = 0.1507</code></pre>
<p>Based on the output of the tests, are the residuals normally
distributed?</p>
<p>Remember, though, there are downsides to this test. When you
interpret the results, be sure to interpret them in the context of your
sample size.</p>
</div>
</div>
<div id="the-log-transform" class="section level3">
<h3>6.2 The log transform</h3>
<p>We have established that our data are normally distributed, but what
if they weren’t? What would we do about it?</p>
<p>If our residuals are not normally-distributed, particularly when we
have skewed data, often a good option is to log transform our data. The
log-transformed data will often be more normally distributed, and if
they are, we can run our test on the log-transformed data. Even though
our residuals are okay in this example, let’s try this transformation on
our grass data and see what effect it has, just for practice!</p>
<p>There is one catch before we do the log transform: we have some
zeroes in our grass cover data, and the log of zero is undefined.
Because there are only a few zeroes, we will add a small values to these
zeroes before doing the transform. Based the the grass cover values,
which are mostly between 0 and 1, we will use 0.01 as our small
value.</p>
<p>To add this value, we first have to figure out which grass cover
values are equal to zero. We can use the handy ‘which’ function, which
tells us which values in a vector fit a particular criteria (in this
case, being equal to zero). We have to input the data frame and variable
names (‘grass$Grass_cover’), as well as the criteria (‘==0’). We will
save the position of the values that fit our criteria in an object
called “indexes”.</p>
<pre class="r"><code>indexes &lt;- which(grass$Grass_cover==0)</code></pre>
<p>We can use the indexes to change the values from zero to 0.01. In the
code below, ‘grass$Grass_cover[indexes]’ will tell R to pull out the
values that we identified as being equal to zero, and ‘&lt;- 0.01’ will
change them to 0.01.</p>
<pre class="r"><code>grass$Grass_cover[indexes] &lt;- 0.01</code></pre>
<p>Now we can log-transform our data and add a new column to the grass
data frame to store our log-transformed grass cover data. I am calling
the new variable “log_Grass_cover”.</p>
<pre class="r"><code>grass$log_Grass_cover &lt;- log(grass$Grass_cover)</code></pre>
<p>Finally, we will check to see if the log transformed data are normal,
using the same approach as above.</p>
<p>First, run the t-test, this time using “log_Grass_cover” as our
dependent variable, save the residuals, and put them in a data
frame.</p>
<pre class="r"><code>grass_ttest_log &lt;- lm(log_Grass_cover~ Weed, data=grass)

resid_log &lt;- resid(grass_ttest_log)

resids_log &lt;- data.frame(Residuals = resid_log)</code></pre>
<p>Now, we will make our graphs to check normality. Start with the
histograms:</p>
<pre class="r"><code>ggplot(resids_log, aes(x=Residuals)) +
  geom_histogram() +
  labs(x=&quot;log Grass Cover&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="RHandbook_6_files/figure-html/residlog_hist-1.png" width="672" /></p>
<p>Next, make the qqplots:</p>
<pre class="r"><code>qqnorm(resid_log)
qqline(resid_log)</code></pre>
<p><img src="RHandbook_6_files/figure-html/qqplots_log-1.png" width="672" /></p>
<p>And finally, we’ll run the Shapiro-Wilks test on the new
residuals:</p>
<pre class="r"><code>shapiro.test(resid_log)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid_log
## W = 0.89604, p-value = 0.004918</code></pre>
<p>Because our residuals were okay to begin with, after log-transforming
the data makes them look worse! It’s definitely better to proceed with
the un-transformed data so far, but we need to check our other
assumption first.</p>
</div>
<div id="testing-for-equal-variances" class="section level3">
<h3>6.3 Testing for equal variances</h3>
<p>Another assumption of linear models is that the variance of our
dependent variable is equal for different values of our independent
variable.</p>
<p>For this one, we do not need to run the models first to save
residuals, so let’s jump right into the testing.</p>
<div id="graphs-to-visualize-variance" class="section level4">
<h4>Graphs to visualize variance</h4>
<p>We will start with a simple visual test: making a box plot to compare
the variation between the different categories.</p>
<pre class="r"><code>ggplot(grass, aes(x=Weed, y=Grass_cover)) +
  geom_boxplot() +
  theme_classic()</code></pre>
<p><img src="RHandbook_6_files/figure-html/cone_boxplot-1.png" width="672" /></p>
<p>It looks like the variances are pretty different between the two
groups, so we seem to have a problem here, but we will look at the
results of a formal test for equal variances too.</p>
</div>
<div id="levenes-test" class="section level4">
<h4>Levene’s test</h4>
<p>Levene’s test is a formal test that will check for equal variances.
Note that is tends to be a bit sensitive, so it will sometimes pick up
small differences in the variances that are not a problem, particularly
if you have large sample sizes. With the Levene’s test, we are testing
the null hypothesis that the variances are equal. Therefore if the
p-value is less than 0.05, that suggests that the variances are not
equal.</p>
<p>The function for the Levene’s test is in the <code>car</code>
package, so install (<code>install.packages("car")</code>) and load that
package first.</p>
<pre class="r"><code>library(car)</code></pre>
<pre><code>## Warning: package &#39;car&#39; was built under R version 4.2.3</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## Warning: package &#39;carData&#39; was built under R version 4.2.3</code></pre>
<p>Now we can run the test:</p>
<pre class="r"><code>leveneTest(Grass_cover ~ Weed, data = grass)</code></pre>
<pre><code>## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value  Pr(&gt;F)  
## group  1  6.0694 0.01971 *
##       30                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Don’t worry if you get a warning message. It is just telling you that
when it ran the test, it converted “Weed” from a character variable to a
factor variable. Take a look at the p-value for the test. Based on this
p-value, are the variances equal?</p>
</div>
</div>
<div id="the-square-root-transform" class="section level3">
<h3>6.4 The square root transform</h3>
<p>We have established that we don’t have equal variance between our
categories, so what can we do? The first thing we can try is
transforming our data. If our data are skewed (not normally
distributed), a log transform might help. However, if our data have a
pretty symmetrical distribution (which we already determined they do), a
log transform is unlikely to help. Instead, we can try a square root
transform. Let’s see if that helps here.</p>
<p>Like with the log transform, we will add a new variable to our data
frame, but this time we will take the square root of our grass cover
variable.</p>
<pre class="r"><code>grass$sqrt_Grass_cover &lt;- sqrt(grass$Grass_cover)</code></pre>
<p>Now, we can use our tests again to see if this helped.</p>
<p>Start with the boxplot:</p>
<pre class="r"><code>ggplot(grass, aes(x=Weed, y= sqrt_Grass_cover)) +
  geom_boxplot() +
  theme_classic()</code></pre>
<p><img src="RHandbook_6_files/figure-html/sqrt_boxplot-1.png" width="672" /></p>
<p>It looks a lot better now, but we will check our Levene’s test
too.</p>
<pre class="r"><code>leveneTest(sqrt_Grass_cover ~ Weed, data = grass)</code></pre>
<pre><code>## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  1  0.1745 0.6791
##       30</code></pre>
<p>Okay, it looks good, so our transform worked. We can now safely run a
t-test using the square-root-transformed data.</p>
</div>
<div id="running-the-test" class="section level3">
<h3>6.5 Running the test</h3>
<p>At this point, we can test the model using either a classical
frequentist approach or a maximum likelihood approach. I will show both
methods here, but, again, note that this is just for the purposes of
demonstration. Normally, you would just choose one approach to use.</p>
<div id="classical-frequentist" class="section level4">
<h4>Classical frequentist</h4>
<p>To run a t-test using the classical frequentist approach, we will use
the same t.test function that we learned in the last lesson. Note,
however, that we now want to use the square-root-transformed variable
(“sqrt_Grass_cover”) instead of the raw grass cover variable.</p>
<pre class="r"><code>grass_ttest_sqrt &lt;- t.test(sqrt_Grass_cover~Weed, data=grass,var.equal=TRUE)
grass_ttest_sqrt</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  sqrt_Grass_cover by Weed
## t = 5.8639, df = 30, p-value = 2.041e-06
## alternative hypothesis: true difference in means between group No removal and group Removal is not equal to 0
## 95 percent confidence interval:
##  0.2846221 0.5888279
## sample estimates:
## mean in group No removal    mean in group Removal 
##                0.7529518                0.3162268</code></pre>
<p>Based on the p-value, would you reject the null hypothesis that weed
removal does not affect end-of-season grass cover?</p>
</div>
<div id="maximum-likelihood-approach" class="section level4">
<h4>Maximum likelihood approach</h4>
<p>Just like the last lesson, to use the maximum likelihood approach, we
start by using the ‘lm’ function to build both the null and alternative
models. Then we use the ‘AIC’ function to compare the AIC values for the
two models. Remember, the model with the lower AIC value is the better
model for our data.</p>
<pre class="r"><code># Build models
grass_null &lt;- lm(sqrt_Grass_cover~1, data=grass)
grass_alt &lt;- lm(sqrt_Grass_cover~Weed, data=grass)

# Compare AIC values
AIC(grass_null, grass_alt)</code></pre>
<pre><code>##            df       AIC
## grass_null  2 17.502090
## grass_alt   3 -4.935758</code></pre>
<p>Which model is best? Is it significantly better than the other
model?</p>
</div>
</div>
<div id="welchs-tests" class="section level3">
<h3>6.6 Welch’s tests</h3>
<p>If the variances still aren’t equal after transforming the data, we
can use a test, called the Welch’s test, that doesn’t assume equal
variances. This will work for both a t-test and and ANOVA. Even though
our square root transform did work in this example, let’s practice how
to do a Welch’s test.</p>
<p>To run the Welch’s test, we will use the same ‘t.test’ function that
we used for a regular t-test, but we will change one argument. Instead
of using the “var.equal=TRUE” setting, we will change it to
“var.equal=FALSE”. Notice that we can run this test will the
un-transformed Grass_cover variable because with this test, it is fine
if the variances are not equal.</p>
<pre class="r"><code>t.test(Grass_cover~Weed,grass,var.equal=FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Grass_cover by Weed
## t = 5.8226, df = 22.549, p-value = 6.711e-06
## alternative hypothesis: true difference in means between group No removal and group Removal is not equal to 0
## 95 percent confidence interval:
##  0.3116919 0.6558079
## sample estimates:
## mean in group No removal    mean in group Removal 
##                0.6169443                0.1331944</code></pre>
<p>The output is similar to what you have seen before. You should see
the t statistic, the degrees of freedom (df) and the p-value. Note that
the df is a little different here that what you would get with a regular
t-test. This is because we lose more degrees of freedom with the
Levene’s test because we are calculating separate variances for each
group.</p>
<p>Note that the conclusion you would draw based on the Welch’s test
using the un-transformed grass cover data is the same conclusion you
would draw using the regular t-test on the square root transformed grass
data.</p>
</div>
<div id="practice-problems" class="section level3">
<h3>Practice problems</h3>
<p>Use the steps below to test out this process on a different data set!
You will work with data on the impact of mycorrhizal inoculation on
plant density. Download the mycorrhizae.csv file from Canvas. When you
are ready to start working with the data in R, be sure to set your
working directly, load the data set, and load the
<strong>ggplot2</strong> package before proceeding.</p>
<ol style="list-style-type: decimal">
<li>What are your null and alternative hypotheses for this
question?</li>
<li>Build model using the ‘lm’ function. Save the model residuals.</li>
<li>Use a histogram and a qqplot to determine if the residuals are
normally-distributed. You may also use a Shapiro-Wilk’s test as a formal
test, if you would like.</li>
<li>Use a boxplot and a Levene’s test to check for equal variances.</li>
<li>Based on your exploration in questions 3 and 4, select an approach
for addressing any violations of the assumptions.</li>
<li>Run an appropriate test (addressing any violations of assumptions)
to answer the original question (Does mycorrhizal inoculation affect
plant density?). You may choose between a classical frequentist or
maximum likelihood when you run this test.</li>
<li>Write you conclusions, including any necessary statistics backing
them up.</li>
</ol>
<p>I will post an answer key to these questions next week.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
