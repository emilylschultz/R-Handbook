<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Emily Schultz" />

<meta name="date" content="2023-02-15" />

<title>ESS 3500 R Handbook, Lesson 10</title>

<script src="site_libs/header-attrs-2.19/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ESS 3500 R Handbook</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="RHandbook_1.html">Lesson 1</a>
</li>
<li>
  <a href="RHandbook_2.html">Lesson 2</a>
</li>
<li>
  <a href="RHandbook_3.html">Lesson 3</a>
</li>
<li>
  <a href="RHandbook_4.html">Lesson 4</a>
</li>
<li>
  <a href="RHandbook_5.html">Lesson 5</a>
</li>
<li>
  <a href="RHandbook_6.html">Lesson 6</a>
</li>
<li>
  <a href="RHandbook_7.html">Lesson 7</a>
</li>
<li>
  <a href="RHandbook_8.html">Lesson 8</a>
</li>
<li>
  <a href="RHandbook_9.html">Lesson 9</a>
</li>
<li>
  <a href="RHandbook_10.html">Lesson 10</a>
</li>
<li>
  <a href="RHandbook_11.html">Lesson 11</a>
</li>
<li>
  <a href="RHandbook_12.html">Lesson 12</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">ESS 3500 R Handbook, Lesson 10</h1>
<h4 class="author">Emily Schultz</h4>
<h4 class="date">2023-02-15</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#lesson-10-assumptions-and-transformations"
id="toc-lesson-10-assumptions-and-transformations">Lesson 10:
Assumptions and Transformations</a>
<ul>
<li><a href="#testing-for-normality" id="toc-testing-for-normality">10.1
Testing for normality</a></li>
<li><a href="#the-log-transform" id="toc-the-log-transform">10.2 The log
transform</a></li>
<li><a href="#testing-for-equal-variances"
id="toc-testing-for-equal-variances">10.3 Testing for equal
variances</a></li>
<li><a href="#the-square-root-transform"
id="toc-the-square-root-transform">10.4 The square root
transform</a></li>
<li><a href="#welchs-tests" id="toc-welchs-tests">10.5 Welch’s
tests</a></li>
</ul></li>
</ul>
</div>

<div id="lesson-10-assumptions-and-transformations"
class="section level2">
<h2>Lesson 10: Assumptions and Transformations</h2>
<p>In this lesson, we will cover how to test two assumptions of linear
models (normality and equal variances) and what to do when the
assumptions are violated</p>
<div id="testing-for-normality" class="section level3">
<h3>10.1 Testing for normality</h3>
<p>Technically, the assumption of linear models is that the residuals
(the leftover variation that is not explained by our model) are normally
distributed. Therefore, in order to test this assumption, we need to run
our model and save the residuals.</p>
<p>For this example, we will work with a new data set on the Coachella
Valley fringe-toed lizard. This lizard is very endangered, so we are
interested in how to best manage the species to improve the chances of
persistence. We have data based on a simulation that estimates the time
to extinction (TTE) for three different management plans: no reserve
(“none”), a single reserve (“single”), and multiple reserves in a
network (“network”).</p>
<p>Download the lizard data and load the data into R.</p>
<pre class="r"><code>lizard &lt;- read.csv(&quot;lizard.csv&quot;)</code></pre>
<p>Now we will build our two models, so we can save the residuals.</p>
<pre class="r"><code>lizard_null &lt;- lm(TTE ~ 1, lizard)
lizard_alt &lt;- lm(TTE~ Plan, lizard)</code></pre>
<p>We will save the residuals from each model using the
<code>resid</code> function. Then we will save the residuals in a data
frame, so we can graph them using <code>ggplot</code>.</p>
<pre class="r"><code>resid_null &lt;- resid(lizard_null)
resid_alt &lt;- resid(lizard_alt)

residuals &lt;- data.frame(resid_null = resid_null, resid_alt = resid_alt)</code></pre>
<div id="histogram-of-residuals" class="section level4">
<h4>Histogram of residuals</h4>
<p>The first way to check for normality of residuals is to make a
histogram to determine if the residuals look like they are normally
distributed, or at least symmetrical.</p>
<pre class="r"><code>library(ggplot2)
ggplot(residuals, aes(x=resid_null)) +
  geom_histogram() +
  labs(x=&quot;Extinction time&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<p><img src="RHandbook_10_files/figure-html/residnull_hist-1.png" width="672" /></p>
<pre class="r"><code>ggplot(residuals, aes(x=resid_alt)) +
  geom_histogram() +
  labs(x=&quot;Extinction time&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<p><img src="RHandbook_10_files/figure-html/residalt_hist-1.png" width="672" /></p>
<p>Do the residuals look normally distributed?</p>
</div>
<div id="qqplot" class="section level4">
<h4>qqplot</h4>
<p>There is another type of graph that is useful for visualizing the
normality of residuals, called a qqplot. This type of graph compares the
residuals from a model with residuals that would be predicted based on a
normal distribution. If we graph the residuals from our model against
the predicted residuals, we would expect them to form a straight line if
the residuals are normally distributed. If they do not form a straight
line, that suggests the residuals are not normally distributed.</p>
<p>To make a qqplot to test for a normal distribution, we can use the
<code>qqnorm</code> function. Then we can ues the <code>qqline</code>
function to add a reference line to the plot, showing where the points
should fall if the data are normally distributed. Let’s make these plots
for both of our models.</p>
<pre class="r"><code>qqnorm(resid_null)
qqline(resid_null)</code></pre>
<p><img src="RHandbook_10_files/figure-html/qqplots-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(resid_alt)
qqline(resid_alt)</code></pre>
<p><img src="RHandbook_10_files/figure-html/qqplots-2.png" width="672" /></p>
<p>When the points form a curve like this, instead of a straight line,
that usually suggests that the data are skewed, which aligns with what
we saw in the histograms. Based on both tests, it looks like our data
are not normally distributed.</p>
</div>
</div>
<div id="the-log-transform" class="section level3">
<h3>10.2 The log transform</h3>
<p>We have established that our data are not normally distributed? What
can we do about it. Well, when we have skewed data like we saw above,
often a good option is to log transform our data. The log tranformed
data will often be more normally distributed, and if they are, we can
run our test on the log-transformed data. Let’s try this on our lizard
data!</p>
<p>First, we will add a new column to our data frame with the log
transformed TTE data.</p>
<pre class="r"><code>lizard$log_TTE &lt;- log(lizard$TTE)</code></pre>
<p>Now we will check to see if the log transformed data are normal,
using the same approach as above.</p>
<p>First, run the two models, this time using “log_TTE” as our dependent
variable, and save the residuals.</p>
<pre class="r"><code>lizard_null_log &lt;- lm(log_TTE ~ 1, lizard)
lizard_alt_log &lt;- lm(log_TTE~ Plan, lizard)

resid_null_log &lt;- resid(lizard_null_log)
resid_alt_log &lt;- resid(lizard_alt_log)

residuals_log &lt;- data.frame(resid_null = resid_null_log, resid_alt = resid_alt_log)</code></pre>
<p>Now, we will make our graphs to check normality. Start with the
histograms:</p>
<pre class="r"><code>ggplot(residuals_log, aes(x=resid_null)) +
  geom_histogram() +
  labs(x=&quot;Extinction time&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<p><img src="RHandbook_10_files/figure-html/residlog_hist-1.png" width="672" /></p>
<pre class="r"><code>ggplot(residuals_log, aes(x=resid_alt)) +
  geom_histogram() +
  labs(x=&quot;Extinction time&quot;, y=&quot;Frequency&quot;) +
  theme_classic()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value
## with `binwidth`.</code></pre>
<p><img src="RHandbook_10_files/figure-html/residlog_hist-2.png" width="672" /></p>
<p>Next, make the qqplots:</p>
<pre class="r"><code>qqnorm(resid_null_log)
qqline(resid_null_log)</code></pre>
<p><img src="RHandbook_10_files/figure-html/qqplots_log-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(resid_alt_log)
qqline(resid_alt_log)</code></pre>
<p><img src="RHandbook_10_files/figure-html/qqplots_log-2.png" width="672" /></p>
<p>They don’t look perfect, but they look much better than before! In
this case, it would be better to use the models with the log transformed
data to draw inferences about the effect of the management plans on the
estimated extinction time of the lizards.</p>
</div>
<div id="testing-for-equal-variances" class="section level3">
<h3>10.3 Testing for equal variances</h3>
<p>Another assumption of linear models is that the variance of our
dependent variable is equal for different values of our independent
variable. To look at this assumption, we are going to return to the
lodgepole pine data set we worked with when you learned to run an ANOVA.
Remember, our question was whether cone size varied between islands
without squirrels (“ia”), islands with squirrels (“ip”), and the
mainland with squirrels (“mp”).</p>
<p>First load the data set, and then we will start testing the
assumption of equal variance.</p>
<pre class="r"><code>cone &lt;- read.csv(&quot;lodgepole.csv&quot;)</code></pre>
<p>For this one, we do not need to run the models first, so let’s jump
right into the testing.</p>
<div id="graphs-to-visualize-variance" class="section level4">
<h4>Graphs to visualize variance</h4>
<p>We will start with a simple visual test: making a box plot to compare
the variation between the different categories.</p>
<pre class="r"><code>ggplot(cone, aes(x=type, y= conesize)) +
  geom_boxplot() +
  theme_classic()</code></pre>
<p><img src="RHandbook_10_files/figure-html/cone_boxplot-1.png" width="672" /></p>
<p>It looks like the variances are pretty similar for the ia and mp
categories, but the ip category has much higher variation. We can check
this with a formal test.</p>
<p>If you are working with two continuous variables, you can make a
scatter plot to check the variance. Just look from left to right along
the graph and see if it looks like the scatter around the best fit line
is about equal.</p>
</div>
<div id="levenes-test" class="section level4">
<h4>Levene’s test</h4>
<p>Levene’s test is a formal test that will check for equal variances.
Note that is tends to be a bit sensitive, so it will sometimes pick up
small differences in the variances that are not a problem, particularly
if you have large sample sizes. With the Levene’s test, we are testing
the null hypothesis that the variances are equal. Therefore if the
p-value is less than 0.05, that suggests that the variances are not
equal.</p>
<p>The function for the Levene’s test is in the <code>car</code>
package, so install (<code>install.packages("car")</code>) and load that
package first.</p>
<pre class="r"><code>library(car)</code></pre>
<pre><code>## Warning: package &#39;car&#39; was built under R version 4.2.3</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## Warning: package &#39;carData&#39; was built under R version 4.2.3</code></pre>
<p>Now we can run the test:</p>
<pre class="r"><code>leveneTest(conesize ~ type, data = cone)</code></pre>
<pre><code>## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value  Pr(&gt;F)  
## group  2  4.7096 0.02895 *
##       13                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Don’t worry if you get a warning message. It is just telling you that
when it ran the test, it converted “type” from a character variable to a
factor variable. Take a look at the p-value for the test. Based on this
p-value, are the variances equal?</p>
</div>
</div>
<div id="the-square-root-transform" class="section level3">
<h3>10.4 The square root transform</h3>
<p>We have established that we don’t have equal variance between are
categories, so what can we do? The first thing we can try is
transforming our data. If our data are skewed (not normally
distributed), a log transform might help. However, if our data have a
pretty symmetrical distribution (which they would for these cone data if
we checked), a log transform is unlikely to help. Instead, we can try a
square root transform. Let’s see if that helps here.</p>
<p>Like with the log tranform, we will add a new variable to our data
frame, but this time we will take the square root of our cone size
variable.</p>
<pre class="r"><code>cone$sqrt_conesize &lt;- sqrt(cone$conesize)</code></pre>
<p>Now, we can use our tests again to see if this helped.</p>
<p>Start with the boxplot:</p>
<pre class="r"><code>ggplot(cone, aes(x=type, y= sqrt_conesize)) +
  geom_boxplot() +
  theme_classic()</code></pre>
<p><img src="RHandbook_10_files/figure-html/sqrt_boxplot-1.png" width="672" /></p>
<p>It still doesn’t look great, but we will check our Levene’s test
too.</p>
<pre class="r"><code>leveneTest(sqrt_conesize ~ type, data = cone)</code></pre>
<pre><code>## Warning in leveneTest.default(y = y, group = group, ...): group coerced to
## factor.</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value  Pr(&gt;F)  
## group  2  5.2235 0.02163 *
##       13                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Okay, it still doesn’t look good, so our transform did not work. But
never fear! Move on to the next section for the solution.</p>
</div>
<div id="welchs-tests" class="section level3">
<h3>10.5 Welch’s tests</h3>
<p>If the variances still aren’t equal after transforming the data, we
can use a test that doesn’t assume equal variances. This will work for
both a t-test and and ANOVA.</p>
<p>To run the Welch’s test for an ANOVA, which is what we need to use
here because our independent variable has three categories, we will use
a new function: <code>oneway.test</code>. This function will allow us to
include an argument indicating that we do not want to assume equal
variances. Otherwise the syntax is the same as for the aov function, and
our hypotheses are the same as they would be for a normal ANOVA. Let’s
run the test.</p>
<pre class="r"><code>oneway.test(conesize~type,cone,var.equal=FALSE)</code></pre>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  conesize and type
## F = 39.747, num df = 2.0000, denom df = 7.6354, p-value = 9.192e-05</code></pre>
<p>The output is similar to what you have seen before. You should see
the F statistic, the degrees of freedom (df) and the p-value. Based on
the p-value, would you reject the null hypothesis that habitat type does
not affect cones size?</p>
<p>We have a bit of a conundrum now, though. Just like a regular ANOVA
the Welch’s ANOVA just does an overall comparison of the categories, so
this output tells us that at least one group is different, but it
doesn’t tell us which group is different. Unfortunately, we can’t use a
Tukey HSD test as a follow up, because the Tukey HSD test does not let
us assume unequal variances. It only works when our variances are equal.
However, we do have another option. We can run pairwise Welch’s t-tests
between our categories, and use a Bonferonni correction to choose a
lower threshold p-value. Let’s work through this process.</p>
<p>First, we need data sets that just have two of the three categories.
We want one data set for each combination of pairs, so we will make
three data sets, excluding one category in each set. To do this, we will
use the <code>filter</code> function from the <strong>tidyverse</strong>
package. In the second argument of the <code>filter</code> fuction, we
will use the <code>!=</code> (does not equal) operator to tell R to
exclude observations with that value for habitat type.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────── tidyverse 1.3.2 ──
## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
## ✔ tidyr   1.3.0      ✔ stringr 1.5.0 
## ✔ readr   2.1.3      ✔ forcats 1.0.0 
## ✔ purrr   1.0.1      
## ── Conflicts ────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()
## ✖ dplyr::recode() masks car::recode()
## ✖ purrr::some()   masks car::some()</code></pre>
<pre class="r"><code>cone_ia_ip &lt;- filter(cone, type != &quot;mp&quot;) 
cone_ia_mp &lt;- filter(cone, type != &quot;ip&quot;)
cone_ip_mp &lt;- filter(cone, type != &quot;ia&quot;) </code></pre>
<p>Now we can run our t-tests on each of these data sets. We’ll start
with the first one and look at the output before moving on to the other
two tests. The only difference in the syntax between the Welch’s t-test
and the regular t-test is that will the change the “var.equal” argument
to “FALSE”.</p>
<pre class="r"><code>t.test(conesize ~ type, data=cone_ia_ip, var.equal=FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  conesize by type
## t = 2.8342, df = 4.8472, p-value = 0.0378
## alternative hypothesis: true difference in means between group ia and group ip is not equal to 0
## 95 percent confidence interval:
##  0.1669797 3.7930203
## sample estimates:
## mean in group ia mean in group ip 
##             8.90             6.92</code></pre>
<p>Look through the output. The p-value from this test is 0.0378.
Normally, we would reject the null hypothesis because it is below 0.05,
but remember, we are doing multiple comparisons here, so we need to
account for that. Doing multiple comparisons makes it more likely that
we will reject the null hypothesis, even if it is true. With the
Bonferonni correction, we choose a new threshold p-value, so that our
overall chance of incorrectly rejecting the null hypothesis is still 5%.
To choose the new threshold, we simply divide 0.05 (are usual threshold)
by the number of comparisons we are making (3, in this example). Our new
threshold is therefore about 0.0167. Based on this new threshold, would
you reject the null hypothesis?</p>
<p>Now we will repeat the Welch’s t-test for our other pairs of habitat
types:</p>
<pre class="r"><code>t.test(conesize ~ type, data=cone_ia_mp, var.equal=FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  conesize by type
## t = 9.2632, df = 8.9492, p-value = 7.01e-06
## alternative hypothesis: true difference in means between group ia and group mp is not equal to 0
## 95 percent confidence interval:
##  2.100514 3.459486
## sample estimates:
## mean in group ia mean in group mp 
##             8.90             6.12</code></pre>
<pre class="r"><code>t.test(conesize ~ type, data=cone_ip_mp, var.equal=FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  conesize by type
## t = 1.149, df = 4.7791, p-value = 0.3048
## alternative hypothesis: true difference in means between group ip and group mp is not equal to 0
## 95 percent confidence interval:
##  -1.015011  2.615011
## sample estimates:
## mean in group ip mean in group mp 
##             6.92             6.12</code></pre>
<p>Look at the output from both of the tests. Using our new threshold
p-value of 0.0167, would you reject the null hypothesis for either
comparison.</p>
<p>Overall, what would you conclude about the effect of habitat on cone
size. Which pair(s) of habitats was significantly different from each
other?</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
