---
title: "ESS 3500 R Handbook, Lesson 7"
author: "Emily Schultz"
date: "2023-02-15"
output: 
  html_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lesson 7: ANOVAs
In the previous lessons, we have been working with t-tests, which are used when you have a categorical independent variable with only 2 values and a continuous dependent variable. In this lesson, we will build on what you have learned and cover ANOVAs. ANOVAs are similar to t-tests, but they can be used when the categorical independent variable has **2 or more** values. In other words, they are are generalization of the t-test. They can be used in for the same type of data as a t-test, but in some additional circumstances as well.

For this lesson, we will work with a new data set on the Coachella Valley fringe-toed lizard. This lizard is very endangered, so we are interested in how to best manage the species to improve the chances of persistence. We have data based on a simulation that estimates the time to extinction (TTE) for three different management plans: no reserve (“none”), a single reserve (“single”), and multiple reserves in a network (“network”).

First, download the lizard data and load the data into R (don't worry if you get a warning message when you do this - it's not a problem).

```{r LoadData}
lizard <- read.csv("lizard.csv")
```

Because when we checked assumptions, we determined that we needed to work with the log-transformed extinction times, we will add the log-transformed variable to our data set:

```{r log}
lizard$log_TTE <- log(lizard$TTE)
```

Also, load the ggplot2 package:

```{r ggplot}
library(ggplot2)
```

Now, we are ready to get started. We will learn both the classical frequentist and likelihood approach.

### 7.1 Frequentist approach
To run an ANOVA with the frequentist approach, the structure is similar to a t-test, but we will use a different function: `aov`. However, the arguments (input) of the function are the same as what we use for a t-test: our independent and dependent variable (don't forget to use the log of TTE) and the data set. To view the output of the test, instead of just typing the name of the test object, we will use the `summary` function, with the test object as the input of the function.

```{r aov}
lizard_anova <- aov(log_TTE ~ Plan, data=lizard)
summary(lizard_anova)
```

As with the t-test, when we view the output, we can see the degrees of freedom (Df), the F value, and the p-value (Pr(>F)). Note that for an ANOVA, we have two degrees of freedom: the between categories degrees of freedom (number of categories - 1) and the within categories degrees of freedom (total sample size - number of categories). We report both when we report our results.

Looking at the p-value, we can see that it is below 0.05, so we reject the null hypothesis and tentatively accept that at least one of our categories has a different time to extinction than the rest.

#### Post-hoc tests
If we want to know specifically which pairs of treatments differ from each other, we can use post-hoc tests to do pairwise comparisons between our categories. This is like running t-tests between each pair of categories, except the test corrects for the problem of multiple comparisons. We will use a function (`pairwise.t.test`) that gives us the flexibility to choose the type of correction we want to do, and will also work for data with unequal variances. We will use the Holm correction, which is a good choice in general because it is not too conservative but also doesn't add other assumptions about our data.

The required inputs of this function are the dependent and independent variables for the test, in that order. There is not a separate argument for the data frame that contains those variables, so we have to provide the data frame nane as part of the variable names. To choose the type of p-value correction we want to use, we also need to add the "p.adjust.method" argument. We set this equal to "holm" to use the Holm correction.

```{r Holm}
pairwise.t.test(lizard$log_TTE,lizard$Plan,p.adjust.method="holm")
```

The output shows a table of p-values for each pairwise comparison between our groups. The row and column names tell you which two groups are being compared. Let's look at the value in the upper left corner. It compares no reserve ("none") to a network of reserves ("network"). The p-value for this pairwise comparison is 0.00005, which is clearly less than 0.05, so that tells us that there is a significant difference in the extinction time between the two treatments.

Now look at the remaining two pairwise comparisons. Based on the p-values, which other pairs of categories had significantly different extinction times?

In this example, it's not necessary because after the log-tranform, our data meet the assumptions of an ANOVA and these follow-up post-hoc tests, but if our data did violate these assumptions, we can adjust the tests we use for the post hoc tests.

If we do not have equal variances, we can still use the `pairwise.t.test` function. We just add an additional argument (pool.sd=FALSE) to the function. If we were going to use this approach for the lizard data, it would look like this:

```{r unequal}
pairwise.t.test(lizard$TTE,lizard$Plan,p.adjust.method="holm",pool.sd=FALSE)
```

To do the pairwise comparisons if we don't have normally-distributed residuals, we need a new function: `pairwise.wilcox.test`. This will run pairwise tests similar to t-test, but that allow for the non-normal distribution. The arguments of this function are the same as the arguments for the `pairwise.t.test` fucntion, so to use this function on the lizard data, it would look like this:

```{r nonnormal}
pairwise.wilcox.test(lizard$TTE,lizard$Plan,p.adjust.method="holm")
```

We interpret the output of these test in the same way we would for the normal pairwise comparisons.

### 7.2 Maximum likelihood approach
To use the maximum likelihood approach for an ANOVA, we use exactly the same procedure that we used for a t-test.

We start by building our null and alternative models, using the `lm` function:

```{r BuildModels}
lizard_null <- lm(log_TTE ~ 1, data=lizard)
lizard_alt <- lm(log_TTE ~ Plan, data=lizard)
```

To compare the models, we again use the `AIC` function:
```{r AIC}
AIC(lizard_null,lizard_alt)
```

What is your conclusion based on the AIC comparison?

If we want to view more information about our models, such as the values of extinction time for each category, we can use the `summary` function. Let's try it just for the alternative model:

```{r summary}
summary(lizard_alt)
```

At the top, you can see the formula you used to build the model, and below that is a table showing the quartiles of your model residuals. Then you can see the coefficients table. The first column of this table ("Estimate") can be used to figure our the time to extinction for each category. The first row in the estimate column (the "intercept" row) is the time to extinction for the network category. We can tell by process of elimination, because the other two row names are "Plannone" and "Plansingle". To calculate the time to extinction for the no reserve category, we take the estimate value in the "Plan none" row and add it to the estimate from the intercept row:

```{r estimate}
-0.51831 + 4.38991
```

You would then use a similar approach to calculate the time to extinction for the single reserve category.

You don't need to understand all of the rest of the output here (but I am happy to answer any questions you have if you are curious!), however, I will point out that the final line provides an F statistic, degrees of freedom, and a p-value that should match the ones from the `aov` function you used for the classical frequentist approach. So you can use the `lm` function for the frequentist approach as well, and just look at the final line from the summary of the alternative model to get the output! 

With the maximum likelihood approach, we do not typically follow up with post-hoc tests. This has to do with differences in the philosophy of the two approaches. Maximum likelihood approaches are more about identifying important explanatory variables for our data and not so much about digging into the nitty-gritty differences between the different categories within a variable. Therefore, if it is important to your question to test for those pairwise differences, you should use the classical frequentist approach.



