---
title: "ESS 3500 R Handbook, Lesson 5"
author: "Emily Schultz"
date: "2023-02-15"
output: 
  html_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lesson 5: LINEAR MODELS IN R
Now that you have learned how to write statistical models (hypotheses), you will learn how to build these models in R. In this process, we will not only write the models, but we will get R to *parameterize* the models for us. What I mean by this is that once we set up the models, R will use our data to estimate the mean and variance for the true distribution of the variable in our population of interest. If we include predictor variables in our model, it will also estimate how the predictor variable affects the mean of our distribution.

### 5.1 Discrete predictor variable
We will start with an example with a discrete (categorical) independent variable and a continuous dependent variable. 

Start off by reading in the civu data set that we have worked with before. Be sure to first set your working directory to the folder with the civu dataset. Then use the `head` function to view the top rows of the data set, as a reminder of what data we have in the data frame.

```{r civu_data}
civu <- read.csv("civu.csv")
head(civu)
```

In this example, we will work with the same question you tackled in your Model Building Practice Problems: does insect herbivory affect the density of thistle plants? For this example we will build 2 models: one representing the null hypothesis and one representing the alternative hypothesis. Then we will practice interpreting the output of the models.

#### Null model
Let's start with the null hypothesis: herbivory does not affect the density of thistles.

To build linear models in R, we will use a new function, the `lm` function (short for "linear model"). The function requires two arguments: the formula for our model and the data set. The formula for our model needs to include the dependent variable on the left side of the formula and the predictor variable(s) on the right side of the formula. For our null model, saying that herbivory does not affect density is the equivalent of saying that we do not need to use herbivory as a predictor in the model. In this case, our null model will therefore not have a predictor variable. We tell R this by putting a 1 in place of a predictor variable.

The full code to set up the model is as follows. We will save the model as an object called "civu_null".

```{r civu_null}
civu_null <- lm(density_2006 ~ 1, civu)
```

Now, lets view the basic output from this model. To do this, we simply type the name of our model object.

```{r view_null}
civu_null
```

This simple output will tell us two things. It will first remind us of the code we used to build the model, so we can see the independent and dependent variables we included. Second, it will show us the coefficients, or the parameters of our model. Because our null model did not have any predictors, it just has a single coefficient, the intercept, which in this case is 34.6. Remember, this model represents the mean of the distribution of our data, so, based on our null model, the mean density is 34.6, regardless of the herbivory treatment.

#### Alternative model
Now, let's compare this null model to our alternative model. Our alternative model is that herbivory does affect the density, so this time, we want it include it as a predictor in our model. We will then be able to see how the herbivory treatment affects our estimate of the mean density.

We set up the model in the same way we did for the null model, but put our predictor variable in place of the 1.

```{r civu_alt}
civu_alt <- lm(density_2006 ~ herbivory, civu)
civu_alt
```

Now when we view the output, we see two coefficients. The intercept (21) and the herbivory coefficient (17). If we wrote this model out as an equation, it would be:

$$
\mu = 21 + 17*herbivory
$$
where \mu is the mean density. Recall that the categorical herbivory term in this equation can take on two values: 0 and 1. In this case, 0 is the control group, which is herbivores present and 1 is the treatment group, which is herbivores excluded. Therefore, the mean density in the presence of herbivores is 21 and the mean density in the absence of herbivores is $21+17=38$.

#### Model variance
We now have two models that describe the mean (or means) of our data:

1. Null model: $\mu=34.6$
2. Alternative model: $\mu=21+17*herbivory$

But remember, to describe data using a normal distribution, we need two parameters: the mean and the variance! We'll now learn how to find the variance ($\sigma^2$) (and standard deviation) in the model output. To do so, we will use the `summary` function. The summary function will give us additional output for our model. Most of the output we will learn about later in the semester when we cover model testing. For now, we will just pull out the standard deviation from the summary for each model as follows:

```{r model_sd}
null_sd_civu <- summary(civu_null)$sigma
alt_sd_civu <- summary(civu_alt)$sigma
```

We can then calculate the variance by squaring the standard deviations:

```{r model_var}
null_var_civu <- null_sd_civu^2
alt_var_civu <- alt_sd_civu^2
```

This variance is specifically what we refer to as the residual variance of the model, which we talked about earlier in the class. It is the variation in our data that is not explained by the predictors we included in our model. In this particular example, we can explain some variation in thistle density by herbivore presence (which is why the residual variance is lower in our alternative model than our null model), but within each treatment groups, there is still unexplained variation in density. In this type of model, we assume that the variance is equal, or close to equal, in both of our treatment groups, so we just have a single variance term.

We now have to complete models, with both mean and variance terms to describe our data. If we write them out formally, they would look like this, where $N$ indicates a normal distribution:

Null model:
$$
density \sim N(\mu,\sigma^2)
$$
$$
\mu = 34.6
$$
$$
\sigma^2 = 12.16
$$

Alternative model:
$$
density \sim N(\mu,\sigma^2)
$$
$$
\mu = 21 + 17*herbivory
$$
$$
\sigma^2 = 10.09
$$

### 5.2 Continuous predictor variable
We will now move on to an example with a continuous independent variable and a continuous dependent variable. 

Read in the DataFrameExample data set that we have worked with before. Be sure to first set your working directory to the folder with the DataFrameExample data set. Because this data set has data on tree growth, we will call it "tree". Again use the `head` function to view the top rows of the data set to remind yourself what data we have in the data frame.

```{r tree_data}
tree <- read.csv("DataFrameExample.csv")
head(tree)
```

For this example, We will also work with the question you tackled in your Model Building Practice Problems for this data set: does temperature affect the growth of trees? Let's build and interpret the null and alternative models for this example! The procedure is the same one used above, we will just interpret the output slightly differently.

#### Null model
Let's start with the null hypothesis: temperature does not affect the growth of trees.

As before, our null model will therefore not have a predictor variable because we are assuming that temperature is not important for the growth of trees.

The full code to set up the model is as follows:

```{r tree_null}
tree_null <- lm( Growth ~ 1, tree)
```

Now, lets view the basic output from this model. 

```{r view_tree_null}
tree_null
```

This output should look very similar to the output for the null model for the civu data. It just has a single coefficient, the intercept because we do not have any predictors. The mean tree growth, based on our null model, is therefore 0.206.

#### Alternative model
Now we'll move on to our alternative model: temperature does affect the tree growth. This time, we will include temperature in our model to determine how the temperature affects tree growth.

We set up the model in the same way we did for the null model, but this time including our temperature variable.

```{r tree_alt}
tree_alt <- lm(Growth ~ Temperature, tree)
tree_alt
```

Here we again see two coefficients. The intercept and the temperature coefficient (i.e., slope). If we wrote this model out as an equation, it would be:

$$
\mu = 0.32926 - 0.01497*temperature
$$
where \mu is the mean tree growth. The difference in the interpretation for this model is that temperature is a continuous variable, so it can take on a full range of values. Still, using this equation, we would be able to calculate the mean tree growth for any temperature value. We can also tell from the sign on the temperature coefficient that as temperature increases, we would expect the tree growth to decrease.

#### Model variance
Finally, we will calculate the residual variance for our two model, so we can fully describe the distribution of our tree growth data.

```{r variation}
null_sd_tree <- summary(tree_null)$sigma
alt_sd_tree <- summary(tree_alt)$sigma

null_var_tree <- null_sd_tree^2
alt_var_tree <- alt_sd_tree^2
```

We are now ready to write our full models, with both mean and variance terms (remember, we just have one variance term for each model), to describe our data.

Null model:
$$
growth \sim N(\mu,\sigma^2)
$$
$$
\mu = 0.206
$$
$$
\sigma^2 = 0.00098
$$

Alternative model:
$$
growth \sim N(\mu,\sigma^2)
$$
$$
\mu = 0.32926 - 0.01497*temperature
$$
$$
\sigma^2 = 0.00093
$$
In the next class, we will use these same examples to practice visualizing our data and model output, so be sure to save your code from this lesson, and make sure you add comments to your code so you remember what you were doing at each step!




