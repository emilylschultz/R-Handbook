---
title: "ESS 3500 R Handbook, Lesson 8"
author: "Emily Schultz"
date: "2023-02-15"
output: 
  html_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 7.2 One-Sample t-tests
We use a one-sample t-test in place of a two-sample t-test when we have a good estimate of the true mean for a variable in our underlying population. This true mean can effectively be used in place of a control group. Rather than having to estimate the true mean from the control group, we already have a value for the true mean that we can then compare to our sample group. For this test, we will only look at the classical frequentist approach.

For simplicity, let's keep working with the civu thistle data set. This time, let's imagine we had good data from a long-term study on the density of thistles in the presence of herbivores. These data provide a good estimate of the true mean thistle density. This true mean density is 28 thistle plants.

For this, we will want to use a data set that only includes observations in the absence of herbivores because that is what we want to compare to the true mean in the presence of herbivores. We'll start by creating that data set:

```{r subset}
library(tidyverse)
civu_noherb <- filter(civu,herbivory == "1")
```

Remember to use the double equals signs to tell R that you are looking for observations that match that criterion.

Now, let's run the t-test using the classical frequentist approach. We will still use the `t.test` function, but this time, because we are just comparing one sample to a true mean, we will not have a predictor variable. Instead of using a formula as the argument, we will provide two arguments: a vector with our data (the density values in the absence of herbivores) and the estimate for the true mean (28).

```{r onettest}
t.test(x = civu_noherb$density_2006, mu = 28)
```

The output includes the same components as the output from the two-sample t-test, but not the difference in the alternative hypothesis. This time, the alternative hypothesis compares the sample mean to the true mean, instead of comparing two sample means.

Based on this output, would you reject or accept the null hypothesis? What does that say about the effect herbivory on thistle density?

#### Visualing one-sample t-test data
We'll wrap up this section by taking a look at one example of how you can visualize the data for a one sample t-test. This graph will be similar to some graphs you have made before; it will by a histogram of your data. However, in this case, instead of having two samples, we have one sample and a value for the true mean in the presence of herbivores. Therefore, we will create a histogram of our sample data with a vertical line (using the `geom_vline` function) showing the true mean. We set the value of the true mean for the vertical line using the "x intercept" argument of the `geom_vline` function.

```{r one_density}
ggplot(data = civu_noherb, aes(x = density_2006))+
  geom_histogram(aes(y=after_stat(density)),fill = "#3b7c70", colour = "#3b7c70" , bins = 6) +
  geom_vline(xintercept = 28, linewidth = 1) +
  labs(x = "Density in 2006", y = "Probability Density") +
  theme_classic()
```

### 7.3 Paired t-tests
Paired sampling designs can be powerful designs for reducing the effects of variation between our samples, allowing us to better detect the effects of our predictor variable. In a paired design, our observations are paired, or matched, in some way. For example, each individual might be subjected to both treatments or we might compare two treatments applied to the same plot. Paired t-tests are a test we can use for paired sampling designs to make comparisons between the two treatments for each individual/sample. The mechanics of this test are actually similar to that of a one-sample t-test! We are comparing the difference in values of our paired samples with a "true" mean of zero.

For this example, we will use a new data set with zinc concentrations at the surface and bottom of a lake. The samples were taken at 10 different locations within the lake. At each site, one sample was taken at the surface and one sample was taken at the bottom. Therefore, we can use a paired t-test to compare between the surface and bottom samples at each location.

#### Frequentist approach
Start by loading your data. Be sure your new zinc data set is in your working directory.

```{r zincdata}
zinc <- read.csv("zinc.csv")
```

Now go ahead and view the entire data set, either using the `View` function or typing the data frame name into your console. One thing I want you to notice about the data set is that if you look at the sample number column, the samples are in the same order, from 1 to 10, for both the bottom and surface samples. When you use the `t.test` function for a paired t-test, it is important for your samples to be in the same order for both of your treatments. Otherwise R will not pair up the values correctly. For the likelihood approach, the order does not matter, as long a you have a column for the sample number.


Next we will run the t-test. The syntax is the same as what you used for a two sample t-test. You will include the formula with your dependent and independent variables as the first argument and the data frame as the second argument. Then we will add one additional argument ("paired = TRUE"), which will tell R to run a paired t-test instead of a normal two-sample t-test.

```{r paired}
paired <- t.test(conc ~ type, data = zinc, paired = TRUE)
```

Again, the output should be similar to what you have seen before. Should you reject the null hypothesis that there is no difference in zinc concentration between the surface and bottom of the lake?

#### Likelihood approach
We will now run the same test using the likelihood approach. To do this, we will be using a function similar to the `lm` function, but which will allow us to account for the paired design. The new function, `lmer`, can be found in the **lme4** package. If you haven't already done so, install the packages using `install.packages("lme4")`. 

Then load the package for this session:

```{r lme4}
library(lme4)
```

We are now ready to run the test. As I said, we will use the `lmer` function, which is very similar to the `lm` function. We will include the same arguments as usual: the formula for our model and the data. The only change we need to make is adding an additional piece to our formula. The syntax for the additional piece is `(1|sampnum)`. This additional piece of the formula will tell R to compare the zinc concentrations at the surface and bottom within each sampling location. We will build both a null an alternative model to compare.

```{r lm_paired}
zinc_null <- lmer(conc ~ 1 + (1|sampnum), data = zinc)
zinc_alt <- lmer(conc ~ type + (1|sampnum), data = zinc)
```

Next, we will use our `AIC` function to compare our null and alternative models to each other:

```{r AIC_paired}
AIC(zinc_null, zinc_alt)
```

The output should have the same structure that it had when we used AIC to compare models for the one sample t-test. Based on this output, which is the better model? (Notice that the AIC values are negative this time, so the better model will be more negative.) What does that tell you about whether zinc concentrations vary between the surface and bottom of the lake?

#### Visualing paired t-test data
There are many ways we could visualize paired t-test data, including a simple boxplot, as we would for a regular two-sample t-test. However, using a boxplot like that would show the full variation in each sample, without accounting for the paired design. A way around that is to instead make a histogram of the *difference* between our paired samples. As we did with the one sample t-test, we will again add a vertical line, this time at 0, to represent the difference we would expect to see under our null hypothesis.

First we need to make a data frame with the difference in zinc concentrations between the surface and the bottom of the lake at each location. We will do this using the `group-by` and `summarise` functions to summarise the difference in concentration for each sample number.

```{r difference}
group <- group_by(zinc,sampnum)
zinc_diff <- summarise(group, diff = diff(conc))
```

Now we can make our histogram using the new `zinc_diff` data frame:

```{r paired_density}
ggplot(data = zinc_diff, aes(x = diff))+
  geom_histogram(aes(y=after_stat(density)),fill = "#3b7c70", colour = "#3b7c70" , bins = 6) +
  geom_vline(xintercept = 0, linewidth = 1) +
  labs(x = "Difference in zinc concentration", y = "Probability Density") +
  theme_classic()
```

### Optional practice problems
For each of the examples

1. Select the appropriate type of t-test
2. State your null and alternative hypotheses
3. Make an appropriate graph to visualize the data
4. Run the t-test
5. State your conclusions

#### Examples
1. A researcher is interested in whether recent declines in the abundance of bees have affected seed set of native plants. For replicate plants, she chose one flower per plant to be a control and another to be hand pollinated. You can look at these data in scroph.csv. The researcher then measured fruit weight to determine how well pollinated the flowers were. Test whether fruit weight different between the control and hand-pollinated flowers.

2. FEV (forced expiratory volume) is an index of pulmonary function that measures the volume of air expelled during 1 second of constant effort.  Our data set (FEV.csv) contains measures of FEV for 654 children ages 3-19 who were seen in the Childhood Respiratory Disease Study in East Boston, Massachusetts in 1980.  These data are part of a longitudinal study to follow the change in pulmonary function over time in children. The data available for each child include: Age (years), FEV (liters), Height (inches), Sex (for this study, classified as male or female), and Smoking Status (current smoker or non-current smoker). Test whether FEV varies between current smokers and non-current smokers.

3. You are working with a group of patients being treated for high blood pressure, and you want to test to see if the treatment is effective. The BloodPressure.csv file contains the latest diastolic blood pressure values for these patients. You know the normal diastolic blood pressure is 80. Test whether the blood pressure of these patients differs from normal.


## Lesson 8: ANOVAs in R
In this lesson, you will move on from t-tests to ANOVAs. The ANOVA (Analysis of Variance) test can be used for similar data types as the t-test: a categorical independent variable and a continuous dependent variable. However, ANOVAs can be used when your independent variable has more than two categories. ANOVAs can, in fact, also be used when your indpendent variable has only two categories, and you would get the same results that you would with a t-test.

### 8.1 One-way ANOVA
The one-way ANOVA is used when we have a single indpendent variable that we would like to test. In future lessons, we will cover how to handle more than one independent variable. For this test, we will use an related to lodgepole pine. Lodgepole pine trees can be found in habitats with different predators, which may have influenced the evolution of their cone morphology. In this example, we will test for differences in the mass of lodgepole pine cones in three different habitats: islands with no squirrel, islands with squirrels, and the mainland (which also has squirrels).

#### Model building and visualization
We'll start off by building our null and alternative models for this question. The approach is exactly the same as the approach we used for the t-test.

First, load the data set. Be sure your working directory is set to the location of the lodgepole data file.

```{r cone_data}
cone <- read.csv("lodgepole.csv")
```

Next, build the two models.

```{r cone_lm}
cone_null <- lm(conesize ~ 1, cone)
cone_alt <- lm(conesize ~ type, cone)
```

To view the output of the model, just type the name of the model. For the null model, it should be pretty simple: just an intercept coefficient representing the overall mean cone mass, regarless of the habitat type. For the alternative model, we now have three coefficients: an intercept, a typeip, and a typemp coefficient. These three values tell us  the means for each habitat. When R runs a linear model with a variable that has multiple categories, it will automatically choose one of the categories as the baseline. The mean for this baseline category is the intercept coefficient. In this case, R used the "ia" category as the baseline. We can tell because the other coefficients are for the type "ip" and the type "mp". The mean mass of cones on the islands without squirrels (ia) is therefore 8.9. To calculate the means for the other group, you add the value of the coefficient for that group to the intercept. To calculate the mean mass of cones on islands with squirrels (ip), for example, you would add 8.9 and -1.98. 

Now, let's create a graph to visualize our data. A boxplot is a good option because, like for the t-test example, we have a categorical independent variable and a continuous dependent variable.

```{r cone_boxplot}
library(ggplot2)
ggplot(cone, aes(x=type, y=conesize)) +
  geom_boxplot() +
  labs(x="Habitat type", y="Mass of cones") +
  theme_classic()
```

#### Classical Frequentist Approach
As usual, we will start off by analyzing the data using a frequentist approach. The syntax for running an ANOVA is similar to the other tests we have run, but this time, we will use the `aov` function. The arguments are still the formula for the model (dependent variable on the left, independent variable on the right) and the data frame.

```{r cone_anova}
cone_ANOVA <- aov(conesize ~ type, data = cone)
```

To view the output, use the `summary` function.

```{r anova_out}
summary(cone_ANOVA)
```

When you view the output, the most important line is the first row of the output table, in this case labeled "type", which was our independent variable. If you look at this row, you will see the F statistic and the p-value for the test. Based on these values, would your reject or accept the null hypothesis? What does this tell you about the effect of habitat on cone mass?

#### Likelihood-based approach
Next we will use a likelihood-based approach to test the same question. Good news! The syntax for this is exactly the same as it was for the t-test. That's because t-tests and ANOVAs are both types of linear models.

We already build our null and alternative models for this problem earlier in the lesson, so we can jump right into using the `AIC` function to compare the models.

```{r cone_aic}
AIC(cone_null, cone_alt)
```

Based on this output, what would you conclude about the effect of habitat on cone size?

### 8.2 Post-hoc tests
But wait! These tests only tells us that cone size is different in at least one of our categories! How do we know which categories actually differ? This is where post-hoc tests come in. Note that we will only use a classical frequentist approach for the post-hoc tests. This is because there are subtle differences in the main goals of the analysis between a classical frequentist approach and a likelihood approach. In a likelihood approach, we are more interested in selecting the best model, rather than drawing specific inferences about individual variables. This is something to keep in mind when choosing the best method for your question. If you are specifically interested in testing the differences between multiple categories, the classical frequentist approach is the better approach to use.

We will now run a Tukey's HSD test, which will do pairwise comparisons between each of our three categories. The Tukey's HSD test will automatically adjust the p-values to account for the fact that we are making multiple comparisons. The syntax for the test is simple. We will use the `TukeyHSD` function, and the argument is the model we created when we ran the ANOVA using the frequentist approach.

```{r tukey}
TukeyHSD(cone_ANOVA)
```

The output you see is the pairwise comparison between each category. The first column of the table shows you which two categories are being compared (ia = islands with no squirrels, ip = islands with squirrels, mp = mainland). The second column tells you the difference in the means of the two categories. The third and forth columns show the lower and upper bounds of the 95% confidence intervals around the mean. Finally, the last column gives you the p-values for the pairwise comparisons.

Based on the p-values, which pairs of habitat types had significant differences in their cone size?

### Optional practice problems
A researcher is interested in comparing the egg size of four different species of birds. The data on the egg length of each species is in the cuckoo.csv data file.

2. State your null and alternative hypotheses
3. Make an appropriate graph to visualize the data
4. Run an ANOVA and post-hoc tests as appropriate
5. State your conclusions


