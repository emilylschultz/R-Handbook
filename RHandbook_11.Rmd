---
title: "ESS 3500 R Handbook, Lesson 11"
author: "Emily Schultz"
date: "2023-04-23"
output: 
  html_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lesson 11: Multiple Predictors
In the previous lessons, we have worked with models that have only one independent and one dependent variable. However, it is common to have more than one independent variable that we would like the test. This is often particularly true when we do observational studies, and there are a whole suite of variable that might affect the response we measure. In this lesson, we will cover models with multiple predictors. We will focus on examples with only two predictors, but the methods can easily be extended to include more than two predictors as well.

### 11.1 Two-way ANOVAs

#### Example 1: millipedes
For our first example, we will work with two categorical predictor variables. We will use a data set from the arthropod world this time, testing whether levels of an amino acid, alanine, vary between different species and different sexes of millipedes.

##### Visualizing and building the models

We'll start off by loading and visualizing our data. Be sure your working directory is set to the location of the millipedes data file. We will also need to change the "species" variable to a factor.

```{r mill_data}
mill <- read.csv("millipedes.csv")
mill$species <- as.factor(mill$species)
```

Now, let's make a box plot to visualize our data set. This will allow us to start looking at the patterns in the data, including possible interactions. We will put species on the x-axis and group and color our boxes by sex. This code includes a new `scale_fill_manual` function that allows us to manually select the colors we want to use. (See [A note about color in R] for more information about using colors in R.)

```{r mill_boxplot}
library(ggplot2)
ggplot(mill, aes(x=species, y=Alanine, fill=sex)) +
  geom_boxplot() +
  scale_fill_manual(values=c("#ce9642","#3b7c70")) +
  labs(x="Species", y="Alanine levels", fill = "Sex") +
  theme_classic()
```

Based just on the graph, what patterns do you see in the data. Does species have an effect? What about sex? Does there appear to be an interaction between the two variables?

Let's proceed with building our models. Now that we are working with two predictor models, we will have multiple alternative models representing four different hypotheses: (1) only sex matters, (2) only species matters, (3) both sex and species matter but don't interact, (4) both sex and species matter and they interact. The models are built in this order after the null model below.

```{r mill_lm}
mill_null <- lm(Alanine ~ 1, data = mill)
mill_sex <- lm(Alanine ~ sex, data = mill)
mill_species <- lm(Alanine ~ species, data = mill)
mill_both <- lm(Alanine ~ sex + species, data = mill)
mill_int <- lm(Alanine ~ sex*species, data = mill)
```

To view the output of your models, type the name of each model. Just like when we have worked with this model before, the null model will have just an intercept. However, the alternative models will have multiple coefficients. Let's take a look at a couple of them.

First, view the coefficients of the `mill_both` model. You should see four coefficients. After the intercept, the first coefficient you will see is labeled "sexm". This is the value you would add to the intercept to get the alanine levels in male millipedes. Then you will see two intercepts for species. The first (species2) tells you what to add to the intercept to get alanine leves for species 2 (for a male of species 2, you would add both the sexm and species2 coefficients). The final coefficient is what you would add to the intercept to get the alanine levels for species 3.

Now, view the coefficients of the `mill_int` model. Now, you will see two additional coefficients representing interactions between the sex and species variables. Based on this model, if you had a male of species 2, in addition to adding the sexm and species2 coefficients, you would also add the sexm:species2 coefficient, which account for how sex interacts with being species 2. For a male of species 3, you would similarly add the coefficient for sexm:species3. 

I personally find it difficult to interpret what the interaction looks like just based on the coefficients. This is where our graphs can come in handy. Looking at our boxplot can help us see the nature of the interaction, if any, between our variables. Based on the graph, do you think the two independent variables interact?

##### Testing the models: Classical Frequentist
To test the models using a frequentist approach, we start with the same `aov` function that we used for a one-way ANOVA. The only difference is that we will include both of our independent variables in our formula. We will set up the formula in the same way we did for our interaction model above, because we want to test both the main effects and the interaction affect. Run the test and look at the output using the code below. Based on the output, we might have to run additional follow-up tests.

```{r mill_2way}
mill_2way <- aov(Alanine ~ sex*species,data=mill)
summary(mill_2way)
```

In the output, you should see a table with a row for each of the main effects (sex and species) and a row showing the results for the interaction between the variables (sex:species). Let's start by looking at the interaction effect, because that affect how we interpret the main effects. We can see from the table that the p-value for the interaction is greater than 0.05, so the interaction affect is not significant. This makes things easier for us because we can interpret the main effects based on the graph and the model coefficients, without worrying about how they interact!

However, just like with a one-way ANOVA, when we have a categorical variable with more than two groups, such a species in this example, the ANOVA only tells us that at least one group is different. It doesn't tell us which specific groups are different. We therefore need to do a post hoc test to look at those pairwise differences. We can use the same `TukeyHSD` function that we used for post hoc tests after a one-way ANOVA. However, because we have more than one independent variable, we can choose to include both variables in the Tukey HSD test or only one variable. In this case, our sex variable has only two groups, so it is not necessary to include it in the post hoc test. We only need to include species, as shown in the code below. (If we needed to include both variable, we would list them both in the `c` function: `which=c("species","sex")`. If you don't list any variables, it will give the results for both variables independently, as well as their interaction.)

```{r mill_tukey}
TukeyHSD(mill_2way,which=c("species"))
```

You interpret this output in the same way you did following the one-way ANOVA. Which pairs of species show significant differences from each other?

##### Testing the models: Likelihood
As we have for previous tests, we will use the `AIC` function to compare our models, but this time we have five different models to compare, instead of just two. We can compare all five at the same time. 

```{r mill_AIC}
AIC(mill_null,mill_sex,mill_species,mill_both,mill_int)
```

Based on the output table, which model was the best? Was it significantly better than the next best model? What do the differences in AIC values tell you about the effects of each predictor and their interaction?

#### Example 2: hypertension
For our second example, we will again work with two categorical predictor variables. We will use a data set from a medical test related to hyptertension. One common cause of hypertension is high sodium levels, which are controlled in part by an enzyme in the kidney called Na-K-ATPase. Researchers tested the activity of Na-K-ATPase in two strains of lab rats: a control strain and a strain selected to spontaneously develop hypertension. They wanted to know if Na-K-ATPase activity varied between these two strains and, if so, what sites in the kidney varied in their enzyme activity. The two independent variables are the rat strain (normal or hypertensive) and the kidney site (DCT, CCD, or OMC).

##### Visualizing and building the models

We'll start off by loading and visualizing our data. Be sure your working directory is set to the location of the kidney data file. 

```{r kidney_data}
kidney <- read.csv("kidney.csv")
```

Now, let's make a box plot to visualize our data set. We will put site on the x-axis and group and color our boxes by lab rat strain. 

```{r kidney_boxplot}
library(ggplot2)
ggplot(kidney, aes(x=site, y=enzyme, fill=hyper)) +
  geom_boxplot() +
  scale_fill_manual(values=c("#ce9642","#3b7c70")) +
  labs(x="Kidney Site", y="Enzyme levels", fill = "Strain") +
  theme_classic()
```

Based just on the graph, what patterns do you see in the data. Do the strains differ in their enzyme activity? What the kidney sites? Does there appear to be an interaction between the two variables?

Let's proceed with building our models. Again, we will have multiple alternative models representing four different hypotheses: (1) only strain matters, (2) only site matters, (3) both strain and site matter but don't interact, (4) both strain and site matter and they interact. The models are built in this order after the null model below.

```{r kidney_lm}
kidney_null <- lm(enzyme ~ 1, data = kidney)
kidney_hyper <- lm(enzyme ~ hyper, data = kidney)
kidney_site <- lm(enzyme ~ site, data = kidney)
kidney_both <- lm(enzyme ~ hyper + site, data = kidney)
kidney_int <- lm(enzyme ~ hyper*site, data = kidney)
```

View the output of your models by typing the name of each model. Based on the model outputs and the graph, without running the tests, how would you describe the patterns in your results.

##### Testing the models: Classical Frequentist
As in the previous example, we will start by using the `aov` function to run the overall two-way ANOVA.

```{r kidney_2way}
kidney_2way <- aov(enzyme ~ hyper*site, data=kidney)
summary(kidney_2way)
```

In the output, you should see a similar table as you saw in the millipede example. Let's start by looking at the interaction effect again. We can see from the table that the p-value for the interaction is less than 0.05, so the interaction affect is significant this time. This makes things trickier because now we can't evaluate each main effect independently. Because the two variables interact, the each main effect depends on the value of the other independent variable.

One way to deal with this non-independence is to split up our data into groups and run multiple one-way ANOVAs (or t-tests, depending on how many categories we have. For example, in this case, we are primarily interested in the difference between normal and hypertensive rats. Therefore, we can split our data into three groups, one for each kidney site, and then run three tests to compare normal and hypertensive rats at each site. 

(Note: We do not want to split our data like this every time we run a two-way ANOVA. We only use this approach when there is a significant interaction.)

A downside of this approach is that we are now running multiple tests on the same data set. We can't use a Tukey HSD test in this particular scenario, but what is another strategy we discussed in the last class that could work here?

Now we will run t-tests to compare the normal and hypertensive rats at each individual kidney site. We will take advantage of two new functions: the `subset` function and the `with` function. The `subset` function will allow us to take a subset of the data containing only the kidney site we want. The `with` function will tell R to apply the t.test to the subset of the data that we took. We include the code for the t-test as the second argument of the `with` function.

```{r kidney_ttest}
with(subset(kidney,site=="CCD"),t.test(enzyme~hyper))
```

Now try adapting this code to run the t-test for the other two sites (DCT and OMCD). Based on the output of the three tests, which kidney sites show differences in enzyme activity between the two strains of mice? Don't forget to adjust your threshold p-value based on the number of tests you ran.

##### Testing the models: Likelihood
Now we will use the likelihood approach and `AIC` function to compare our models, just like we did with the millipede models. 

```{r kidney_AIC}
AIC(kidney_null,kidney_hyper,kidney_site,kidney_both,kidney_int)
```

Based on the output table, which model was the best? Was it significantly better than the next best model? What do the differences in AIC values tell you about the effects of each predictor and their interaction?


### 11.2 Two continuous predictors (multiple regression)
For our next example, we will work with two continuous predictor variable, sometimes called a multiple regression. We will use the carbon storage data set that we worked with once before, but this time will will look at some additional variables and consider how the levels of active bacteria and active fungi in the soil affect total carbon storage.

#### Visualizing and building the models
First, load the data.

```{r carbon_data}
carbon <- read.csv("carbon.csv")
```

There are many variables in the data set, but we will just focus on a few. "Tc" will be our response variable and "Active_Bacteria" and "Active_Lifespan" will be our two predictor variables.

Now let's graph our data. It is challenging to visualize two continuous predictor variable at the same time (I think 3D graphs are hard to read). One option is just to make separate scatter plots for each predictor, but that does not allow you to see interactions between the two variables. What I often do is convert one of the predictors to a categorical variable (just for the graph, not for the test), and graph both of the predictors at the same time. We'll try that.

First, we will use the `mutate` function to create a new variable that converts active fungi to a category. We will just use two categories: high and low. High active fungi will be anything above the median active fungi from our data set, and low weight will be anything less than or equal to the median. To to this, we will use the `ifelse` function. This function allows us to set a value for something **if** it matches certain criteria (in this case, if the active fungi is greater than the median) and set a different values if it does not match the criteria.

```{r fungi_cat}
library(tidyverse)

med <- median(carbon$Active_Fungi)
carbon <- mutate(carbon,Fungi_cat = ifelse(Active_Fungi > med, "High", "Low"))
```

If you view the data set, you will now see a new variable called "Weight_cat" that we will use to graph our data. Let's make that graph now. We will use "Lifespan" as our x variable, and we will use two different colors to represent our two weight categories.

```{r carbon_scat}
ggplot(data=carbon, aes(x=Active_Bacteria,y=Tc,color=Fungi_cat)) +
  geom_point() +
  geom_smooth(method="lm") +
  scale_color_manual(values=c("#ce9642","#3b7c70")) +
  labs(x="Active bacteria", y="Total carbon storage",color="Active fungi") +
  theme_classic()
```

What are your initial interpretations based on the graph?

Now, let's build our models. Just like our first example, we will have multiple alternative models that we test.

```{r carbon_lm}
carbon_null <- lm(Tc ~ 1, data = carbon)
carbon_bac <- lm(Tc ~ Active_Bacteria, data = carbon)
carbon_fungi <- lm(Tc ~ Active_Fungi, data = carbon)
carbon_both <- lm(Tc ~ Active_Bacteria + Active_Fungi, data = carbon)
carbon_int <- lm(Tc ~ Active_Bacteria*Active_Fungi, data = carbon)
```

Look at the summaries for some of your models. Do the coefficients for the different variable make sense based on what you saw in your graph?
  
  We will again check our assumption of normality before testing the models.

```{r carbon_resid}
resid_null_carbon <- resid(carbon_null)
resid_bac_carbon <- resid(carbon_bac)
resid_fungi_carbon <- resid(carbon_fungi)
resid_both_carbon <- resid(carbon_both)
resid_int_carbon <- resid(carbon_int)
```

```{r carbon_qq}
qqnorm(resid_null_carbon)
qqline(resid_null_carbon)

qqnorm(resid_bac_carbon)
qqline(resid_bac_carbon)

qqnorm(resid_fungi_carbon)
qqline(resid_fungi_carbon)

qqnorm(resid_both_carbon)
qqline(resid_both_carbon)

qqnorm(resid_int_carbon)
qqline(resid_int_carbon)
```

Yikes, this time, it looks like we have some skew in our data based on the curved shape of the points in our qqplots. Before we run the tests, we'll try a log transform to see if that makes our residuals less skewed. We can actually do this transform right in the formula of our linear model, instead of adding a new variable. We will just add the `log` function to our dependent variable (Tc).

```{r logcarbon_lm}
carbon_null <- lm(log(Tc) ~ 1, data = carbon)
carbon_bac <- lm(log(Tc) ~ Active_Bacteria, data = carbon)
carbon_fungi <- lm(log(Tc) ~ Active_Fungi, data = carbon)
carbon_both <- lm(log(Tc) ~ Active_Bacteria + Active_Fungi, data = carbon)
carbon_int <- lm(log(Tc) ~ Active_Bacteria*Active_Fungi, data = carbon)
```

Look at the summaries for some of your models. Do the coefficients for the different variable make sense based on what you saw in your graph?

Now, we will check the residuals again, using the models with the log transformed data.

```{r logcarbon_resid}
resid_null_carbon <- resid(carbon_null)
resid_bac_carbon <- resid(carbon_bac)
resid_fungi_carbon <- resid(carbon_fungi)
resid_both_carbon <- resid(carbon_both)
resid_int_carbon <- resid(carbon_int)
```

```{r logcarbon_qq}
qqnorm(resid_null_carbon)
qqline(resid_null_carbon)

qqnorm(resid_bac_carbon)
qqline(resid_bac_carbon)

qqnorm(resid_fungi_carbon)
qqline(resid_fungi_carbon)

qqnorm(resid_both_carbon)
qqline(resid_both_carbon)

qqnorm(resid_int_carbon)
qqline(resid_int_carbon)
```

These look better now, so we'll move on with testing our models.

#### Testing the models
To test the models, we will use the same approach that we used with the first example.

```{r carbon_AIC}
AIC(carbon_null,carbon_bac,carbon_fungi,carbon_both,carbon_int)
```

Based on the AIC models, which model is the best? Is it significantly better than the others? Given this, along with the coefficients from the best model and the patterns you see in your graph, what can you conclude about the effects of the two predictor variables (bacteria and fungi levels)?
  
  ### 11.3 Continuous and categorial predictors
  For our final example, we will look at a blend of the previous two types of predictors and consider a case where we have one continuous and one categorical predictor. We will use an example of butterfly endurance and how it is affected by both temperature and the genotype of the butterfly.

#### Visualizing and building the models

```{r butterfly_data}
butterfly <- read.csv("butterfly.csv")
```

```{r butterfly_scat}
ggplot(data=butterfly, aes(x=Temp,y=Endurance,color=Genotype)) +
  geom_point() +
  geom_smooth(method="lm") +
  scale_color_manual(values=c("#ce9642","#3b7c70","#3b3a3e")) +
  labs(x="Temperature") +
  theme_classic()
```

What is your initial interpretation for how temperature and genotype affect the endurance of butterflies, based on the graph? Does unequal variances seem to be a problem?
  
  We will now move on to building our models: one null model and our four different alternative models.

```{r butterfly_lm}
butter_null <- lm(Endurance ~ 1, data=butterfly)
butter_temp <- lm(Endurance ~ Temp, data=butterfly)
butter_geno <- lm(Endurance ~ Genotype, data=butterfly)
butter_both <- lm(Endurance ~ Temp + Genotype, data=butterfly)
butter_int <- lm(Endurance ~ Temp*Genotype, data=butterfly)
```

Before testing these models, we'll check our residuals for normality.

```{r butterfly_resid}
resid_null_butter <- resid(butter_null)
resid_temp_butter <- resid(butter_temp)
resid_geno_butter <- resid(butter_geno)
resid_both_butter <- resid(butter_both)
resid_int_butter <- resid(butter_int)
```

```{r butterfly_qq}
qqnorm(resid_null_butter)
qqline(resid_null_butter)

qqnorm(resid_temp_butter)
qqline(resid_temp_butter)

qqnorm(resid_geno_butter)
qqline(resid_geno_butter)

qqnorm(resid_both_butter)
qqline(resid_both_butter)

qqnorm(resid_int_butter)
qqline(resid_int_butter)
```

Once again, the residuals don't look quite normal, but there doesn't seem to be a lot of skew, so we'll move on with testing our models.

#### Testing the models
Using the likelihood approach, we can again just use the `AIC` function to compare our five models:
  
  ```{r butterfly_AIC}
AIC(butter_null,butter_temp,butter_geno,butter_both,butter_int)
```

Based on these AIC values, what can you conclude about the effects of temperature, genotype, and their interaction on butterfly endurance?

### Optional practice problems
Download the algae.csv file from Canvas. This data set contains data on the growth of algae under 4 different light levels (low, med low, med high, and high) and three different wave intensity (low, med, high). Researchers want to know if the light level and wave intensity affect algae growth. For the algae growth variable, we will be working with the natural log of growth (log_growth).

1. Write the null and alternative hypotheses for the main effects and the interaction effect.

2. Make a box plot to visualize the effect of both independent variables (light and wave) on algae growth.

3. Run a two-way ANOVA using the classical frequentist approach. Run any follow-up tests as necessary.

4. Build and compare your models using the likelihood approach. Don't forget to build models for both predictors individually, the predictors together, and the predictor together plus their interaction.

5. State your conclusions from your analysis, including all necessary statistics.
